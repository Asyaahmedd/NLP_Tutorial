{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Normalization\n",
    "\n",
    "We use lots of variations for same words for examples user might express love in different ways `[lovely, luv, loveee, ...]` all these are the essentially the same to a machine learning model that tries to find out if a review is positive or negative.\n",
    "\n",
    "So in this notebook we will discuss some methods to reduce text variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stemming\n",
    "\n",
    "Stemming reduce the text  by a set of pre-defined rules like removing `ing` from verbs.\n",
    "\n",
    "Definition: Stemming is the process of removing prefixes and suffixes from words in order to obtain their common base form. The result of stemming is often a root word, which may not be a valid word but still represents the core meaning of the word.\n",
    "\n",
    "Simplicity: Stemming is a heuristic process that applies simple rules to reduce words. It doesn't consider the context of the word.\n",
    "\n",
    "Example: For example, stemming might reduce words like \"jumping,\" \"jumps,\" and \"jumped\" to the root \"jump.\"\n",
    "\n",
    "Speed: Stemming is generally faster and computationally less intensive compared to lemmatization.\n",
    "\n",
    "Use Cases: Stemming is commonly used in information retrieval tasks, such as search engines and document retrieval, where speed is crucial. It's also used in text classification and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress, fli, die, mule, deni, die, agre, own, humbl, size, meet, state, siez, item, sensat, tradit, refer, colon, plot\n"
     ]
    }
   ],
   "source": [
    "# Import the PorterStemmer class from the nltk.stem.porter module\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create an instance of the PorterStemmer class\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a list of plural words to be stemmed\n",
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "           'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "           'meeting', 'stating', 'siezing', 'itemization',\n",
    "           'sensational', 'traditional', 'reference', 'colonizer',\n",
    "           'plotted']\n",
    "\n",
    "# Use the stemmer to stem each word in the 'plurals' list and store the results in 'singles'\n",
    "singles = [stemmer.stem(plural) for plural in plurals]\n",
    "\n",
    "# Print the stemmed words, joined by commas\n",
    "print(', '.join(singles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Snowball stemmer support different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T13:33:33.369154Z",
     "start_time": "2021-11-07T13:33:33.360661Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic, danish, dutch, english, finnish, french, german, hungarian, italian, norwegian, porter, portuguese, romanian, russian, spanish, swedish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "print(\", \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T13:36:37.247468Z",
     "start_time": "2021-11-07T13:36:37.236091Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'جو سماوه صاف'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_stemmer = SnowballStemmer(\"arabic\")\n",
    "ar_stemmer.stem(\"الجو سماؤه صافية\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lemmatization\n",
    "\n",
    "Lemmatizer reduce the word by looking it up in the `WordNet` where it tries to find the root of the word for example `rocks` -> `rock`.\n",
    "\n",
    "Definition: Lemmatization is the process of reducing words to their base or dictionary form (lemma) while considering their context, linguistic rules, and part of speech. The result of lemmatization is a valid word that represents the base form of the word.\n",
    "\n",
    "Context Awareness: Lemmatization takes into account the context and meaning of words, ensuring that the resulting base form is a real word and not just a character-stripped root.\n",
    "\n",
    "Example: For example, lemmatization would reduce words like \"better,\" \"best,\" and \"good\" to the lemma \"good\" because they all convey a similar meaning.\n",
    "\n",
    "Accuracy: Lemmatization is more accurate than stemming but can be slower and more computationally intensive because it involves dictionary lookups and linguistic analysis.\n",
    "\n",
    "Use Cases: Lemmatization is often used in applications where accuracy and interpretation of text are important, such as text summarization, machine translation, sentiment analysis, and language generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# Import the WordNetLemmatizer class from the nltk.stem module\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create an instance of the WordNetLemmatizer class named 'lemmatizer'\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Perform lemmatization on different words and print the results\n",
    "\n",
    "# Lemmatize the word \"rocks\" (default behavior treats it as a noun)\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "\n",
    "# Lemmatize the word \"corpora\" (default behavior treats it as a noun)\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# Lemmatize the word \"better\" with the part of speech (pos) specified as \"a\" (adjective)\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lemmatization vs Stemming\n",
    "\n",
    "The key concept here is that stemming sometime destroy the word unlike lemmatization where we keep the meaning.\n",
    " \n",
    "In summary, the key differences between stemming and lemmatization lie in their approaches and outputs. Stemming is a faster but less accurate technique that strips words to their roots, while lemmatization is a more accurate but computationally intensive process that reduces words to valid dictionary forms based on context and part of speech. The choice between stemming and lemmatization depends on the specific NLP task and the trade-offs between speed and accuracy."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
